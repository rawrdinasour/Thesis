{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/usr/local/lib/python3.9/site-packages\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk, pandas as pd, numpy as np\n",
    "import re\n",
    "from nltk.parse.corenlp import CoreNLPParser, CoreNLPDependencyParser\n",
    "from nltk.tree import ParentedTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dep_parser = CoreNLPDependencyParser(url='http://0.0.0.0:9000')\n",
    "pos_tagger = CoreNLPParser(url='http://0.0.0.0:9000', tagtype='pos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_sentence (input_sent):\n",
    "    # Parse sentence using Stanford CoreNLP Parser\n",
    "    pos_type = pos_tagger.tag(input_sent.split())\n",
    "    parse_tree, = ParentedTree.convert(list(pos_tagger.parse(input_sent.split()))[0])\n",
    "    dep_type, = ParentedTree.convert(dep_parser.parse(input_sent.split()))\n",
    "    return pos_type, parse_tree, dep_type\n",
    "\n",
    "def multi_liaison (input_sent, output=['tagging','parse_tree','type_dep','spo','relation']):\n",
    "    pos_type, parse_tree, dep_type = convert_sentence(input_sent)\n",
    "    pos_sent = ' '.join([x[0]+'/'+x[1] for x in pos_type])\n",
    "    # Extract subject, predicate and object\n",
    "    subject, adjective = get_subject(parse_tree)\n",
    "    predicate = get_predicate(parse_tree)\n",
    "    objects = get_object(parse_tree)\n",
    "    # Generate the relations between subjects and objects\n",
    "    relation = get_relationship(dep_type, subject, predicate, objects)\n",
    "    if 'tagging' in output:\n",
    "        print('---TAGGING---')\n",
    "        print(pos_sent)\n",
    "        print()\n",
    "    if 'parse_tree' in output:\n",
    "        print('---PARSE TREE---')\n",
    "        parse_tree.pretty_print()\n",
    "        print()\n",
    "    if 'type_dep' in output:\n",
    "        print('---TYPED DEPENDENCIES---')\n",
    "        li = []\n",
    "        for x in dep_type.triples(): li.append(list(x))\n",
    "        return li\n",
    "        print()\n",
    "    if 'spo' in output:\n",
    "        print('---MULTI-LIAISON OUTPUT---')\n",
    "        print('Subject: ',len(subject))\n",
    "        for x in subject: print(' '.join(x))\n",
    "        print('Predicate: ',len(predicate))\n",
    "        for x in predicate: print(' '.join(x))\n",
    "        print('Object: ',len(objects))\n",
    "        for x in objects: print(' '.join(x))\n",
    "        print()\n",
    "    if 'relation' in output:\n",
    "        print('---RELATIONSHIP---')\n",
    "        for x in relation: print(x)\n",
    "\n",
    "def get_subject (parse_tree):\n",
    "    # Extract the nouns and adjectives from NP_subtree which is before the first / main VP_subtree\n",
    "    subject, adjective = [],[]\n",
    "    for s in parse_tree:\n",
    "        if s.label() == 'NP':\n",
    "            for t in s.subtrees(lambda y: y.label() in ['NN','NNP','NNS','NNPS','PRP']):\n",
    "                # Avoid empty or repeated values\n",
    "                if t.pos()[0] not in subject:\n",
    "                    subject.append(t.pos()[0])\n",
    "            for t in s.subtrees(lambda y: y.label().startswith('JJ')):\n",
    "                if t.pos()[0] not in adjective:\n",
    "                    adjective.append(t.pos()[0])\n",
    "    return subject, adjective\n",
    "\n",
    "def get_predicate (parse_tree):\n",
    "    # Extract the verbs from the VP_subtree\n",
    "    predicate = []\n",
    "    for s in parse_tree.subtrees(lambda x: x.label() == 'VP'):\n",
    "        for t in s.subtrees(lambda y: y.label().startswith('VB')):\n",
    "            if t.pos()[0] not in predicate:\n",
    "                predicate.append(t.pos()[0]) \n",
    "    return predicate\n",
    "\n",
    "def get_object (parse_tree):\n",
    "    # Extract the nouns from VP_NP_subtree\n",
    "    objects, output = [],[]\n",
    "    for s in parse_tree.subtrees(lambda x: x.label() == 'VP'):\n",
    "        for t in s.subtrees(lambda y: y.label() == 'NP'):\n",
    "            for u in t.subtrees(lambda z: z.label() in ['NN','NNP','NNS','NNPS','PRP$']):\n",
    "                output = u.pos()[0]\n",
    "                if u.left_sibling() is not None and u.left_sibling().label().startswith('JJ'):\n",
    "                    output += u.left_sibling().pos()[0]\n",
    "                if output not in objects:\n",
    "                    objects.append(output)\n",
    "    return objects\n",
    "\n",
    "def get_relationship (dep_type, subject, predicate, objects):\n",
    "    # Generate relations based on the relationship dependencies obtained from parse_tree.triples()\n",
    "    subject = [x[0] for x in subject]\n",
    "    predicate = [x[0] for x in predicate]\n",
    "    objects = [x[0] for x in objects]     \n",
    "    d1, d2, r1, r2, relation, s1, s2, subjs = [],[],[],[],[],[],[],[]\n",
    "    w1, w2, output = '','',''\n",
    "    for head, rel, dep in dep_type.triples():\n",
    "        if rel in ['nsubj','acl:relcl','conj']:\n",
    "            s1, s2 = head[0], dep[0]\n",
    "            if s2 in subject and s1 in predicate:\n",
    "                w1, w2 = s2, s1\n",
    "            elif s2 in predicate and (s1 in subject or s1 in objects):\n",
    "                w1, w2 = s1, s2\n",
    "            elif s2 in subject and s1 in subject:\n",
    "                subjs = [s1, s2]\n",
    "            if w1 != '' and w2 != '':\n",
    "                r1 = [w1, w2]\n",
    "        if rel in ['dobj','prep','nmod','conj']:\n",
    "            d1, d2 = head[0], dep[0]\n",
    "            if d1 in objects and d2 in objects: \n",
    "                r2 = [d1,d2]\n",
    "            elif d2 in objects:\n",
    "                r2 = [d2]\n",
    "            elif d1 in objects:\n",
    "                r2 = [d1]\n",
    "        if len(r1) != 0 and len(r2) != 0 and (r2[0] not in r1 and r2[-1] not in r1):\n",
    "            if len(subjs) != 0:\n",
    "                for n in subjs:\n",
    "                    output = '-'.join([n] + r1[-1:] + r2)\n",
    "                    if output not in relation:\n",
    "                        relation.append(output)\n",
    "            else:\n",
    "                output = '-'.join(r1+r2)\n",
    "                if output not in relation:\n",
    "                    relation.append(output)  \n",
    "    rm = [x for x in relation for y in relation if x != y and re.match(x,y)]\n",
    "    for x in rm: \n",
    "        if x in relation:\n",
    "            relation.remove(x)    \n",
    "    return relation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---TAGGING---\n",
      "Sometimes/RB I/PRP feel/VBP not/RB tired/JJ and/CC not/RB sleepy/JJ ,/, but/CC always/RB very/RB angry/JJ and/CC mad/JJ ./. I/PRP am/VBP sad/JJ ./. I/PRP am/VBP very/RB hungry/JJ ./.\n",
      "\n",
      "---PARSE TREE---\n",
      "                                                                         S                                                                    \n",
      "                                              ___________________________|__________________________________________________________________   \n",
      "                                             S                                        |                    |                                | \n",
      "     ________________________________________|_____                                   |                    |                                |  \n",
      "    |      |                                       VP                                 |                    S                                | \n",
      "    |      |    ___________________________________|___                               |        ____________|___________                     |  \n",
      "    |      |   |    |                                 ADJP                            |       S                        S                    | \n",
      "    |      |   |    |          ________________________|_________________             |    ___|____________     _______|___                 |  \n",
      "    |      |   |    |        ADJP                  |   |                 |            |   |       VP       |   |           VP               | \n",
      "    |      |   |    |     ____|________            |   |                 |            |   |    ___|___     |   |    _______|____            |  \n",
      "   ADVP    NP  |    |   ADJP  |       ADJP         |   |                ADJP          |   NP  |      ADJP  |   NP  |           ADJP         | \n",
      "    |      |   |    |    |    |     ___|_____      |   |      ___________|________    |   |   |       |    |   |   |        ____|_____      |  \n",
      "    RB    PRP VBP   RB   JJ   CC   RB        JJ    ,   CC    RB    RB    JJ   CC  JJ  .  PRP VBP      JJ   .  PRP VBP      RB         JJ    . \n",
      "    |      |   |    |    |    |    |         |     |   |     |     |     |    |   |   |   |   |       |    |   |   |       |          |     |  \n",
      "Sometimes  I  feel not tired and  not      sleepy  ,  but  always very angry and mad  .   I   am     sad   .   I   am     very      hungry  . \n",
      "\n",
      "\n",
      "---TYPED DEPENDENCIES---\n"
     ]
    }
   ],
   "source": [
    "li = multi_liaison(\"Sometimes I feel not tired and not sleepy, but always very angry and mad. I am sad. I am very hungry.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('feel', 'VBP'), 'advmod', ('Sometimes', 'RB')],\n",
       " [('feel', 'VBP'), 'nsubj', ('I', 'PRP')],\n",
       " [('feel', 'VBP'), 'xcomp', ('tired', 'JJ')],\n",
       " [('tired', 'JJ'), 'advmod', ('not', 'RB')],\n",
       " [('tired', 'JJ'), 'conj', ('sleepy', 'JJ')],\n",
       " [('sleepy', 'JJ'), 'cc', ('and', 'CC')],\n",
       " [('sleepy', 'JJ'), 'advmod', ('not', 'RB')],\n",
       " [('feel', 'VBP'), 'punct', (',', ',')],\n",
       " [('feel', 'VBP'), 'conj', ('angry', 'JJ')],\n",
       " [('angry', 'JJ'), 'cc', ('but', 'CC')],\n",
       " [('angry', 'JJ'), 'advmod', ('always', 'RB')],\n",
       " [('angry', 'JJ'), 'advmod', ('very', 'RB')],\n",
       " [('angry', 'JJ'), 'conj', ('mad', 'JJ')],\n",
       " [('mad', 'JJ'), 'cc', ('and', 'CC')],\n",
       " [('feel', 'VBP'), 'punct', ('.', '.')],\n",
       " [('feel', 'VBP'), 'parataxis', ('sad', 'JJ')],\n",
       " [('sad', 'JJ'), 'nsubj', ('I', 'PRP')],\n",
       " [('sad', 'JJ'), 'cop', ('am', 'VBP')],\n",
       " [('feel', 'VBP'), 'punct', ('.', '.')],\n",
       " [('feel', 'VBP'), 'parataxis', ('hungry', 'JJ')],\n",
       " [('hungry', 'JJ'), 'nsubj', ('I', 'PRP')],\n",
       " [('hungry', 'JJ'), 'cop', ('am', 'VBP')],\n",
       " [('hungry', 'JJ'), 'advmod', ('very', 'RB')],\n",
       " [('feel', 'VBP'), 'punct', ('.', '.')]]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "li"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_behavior(li):\n",
    "    behaviors = {}\n",
    "    for group in li:\n",
    "        if (group[0][1].startswith('JJ') or group[0][1].startswith('VB')) and group[0][0] not in behaviors:\n",
    "            behaviors[group[0][0]] = []\n",
    "        if group[2][1].startswith('RB') and group[0][0] in behaviors.keys():\n",
    "            behaviors[group[0][0]].append(group[2][0])\n",
    "    return behaviors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'feel': ['Sometimes'],\n",
       " 'tired': ['not'],\n",
       " 'sleepy': ['not'],\n",
       " 'angry': ['always', 'very'],\n",
       " 'mad': [],\n",
       " 'sad': [],\n",
       " 'hungry': ['very']}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_behavior(li)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"Narratives-Per-Line.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"report\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[\"behavior\"] = df[\"report\"].apply(lambda row : get_behavior(multi_liaison(row)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"output.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_excel(\"News.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df2[\"behavior\"] = df2[\"First Paragraph\"].apply(lambda row : get_behavior(multi_liaison(str(row))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.to_csv(\"news_output.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
